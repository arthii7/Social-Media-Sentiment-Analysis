# -*- coding: utf-8 -*-
"""Sentiment analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IubGS9jTLzd_9_-T0l-gcuIuZn5aTxPE
"""

!mkdir -p ~/.c
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d arkhoshghalb/twitter-sentiment-analysis-hatred-speech

import zipfile
zip_ref=zipfile.ZipFile('/content/twitter-sentiment-analysis-hatred-speech.zip','r')
zip_ref.extractall('/content')
zip_ref.close()

import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences,to_categorical
from keras.layers import SimpleRNN,Dense,Embedding

df_train=pd.read_csv('/content/train.csv')
df_train.head()

X=df_train['tweet']
y=df_train['label']

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

tokenizer=Tokenizer(num_words=1000,lower=True)

tokenizer.fit_on_texts(X_train)

tokenizer.word_index

X_train=tokenizer.texts_to_sequences(X_train)
X_test=tokenizer.texts_to_sequences(X_test)

vocab_size=len(tokenizer.word_index)+1
vocab_size

X_train=pad_sequences(X_train,maxlen=100,padding='post')
X_test=pad_sequences(X_test,maxlen=100,padding='post')

y_train=to_categorical(y_train,num_classes=2)
y_test=to_categorical(y_test,num_classes=2)

y_train.shape

X_train=np.array(X_train).reshape((X_train.shape[0],X_train.shape[1],1))
X_test=np.array(X_test).reshape((X_test.shape[0],X_test.shape[1],1))

model=Sequential()
maxlen=100

model.add(SimpleRNN(50,input_shape=(maxlen,1),return_sequences=False))
model.add(Dense(2,activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(X_train,y_train,validation_data=(X_test,y_test))

model=Sequential()
maxlen=100
model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=maxlen))
model.add(SimpleRNN(50,input_shape=(maxlen,1),return_sequences=False))
model.add(Dense(2,activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(X_train,y_train,validation_data=(X_test,y_test))

